{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3ed0a5",
   "metadata": {},
   "source": [
    "1. Explique com as suas palavras as diferenÃ§as entre RegressÃ£o Linear MÃºltipla, RegressÃ£o Lasso e RegressÃ£o de Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9d4cf",
   "metadata": {},
   "source": [
    "ğŸ‡§ğŸ‡· Portugues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e97f88",
   "metadata": {},
   "source": [
    "### DiferenÃ§as entre RegressÃ£o Linear MÃºltipla, RegressÃ£o Lasso e RegressÃ£o de Ridge\n",
    "\n",
    "A **RegressÃ£o Linear MÃºltipla**, a **RegressÃ£o Lasso** e a **RegressÃ£o de Ridge** sÃ£o tÃ©cnicas de regressÃ£o utilizadas para modelar a relaÃ§Ã£o entre variÃ¡veis independentes (preditoras) e uma variÃ¡vel dependente (alvo). Aqui estÃ£o as diferenÃ§as principais entre elas:\n",
    "\n",
    "#### 1. RegressÃ£o Linear MÃºltipla\n",
    "- Ã‰ a forma bÃ¡sica de regressÃ£o linear que tenta ajustar um modelo linear simples aos dados.\n",
    "- NÃ£o possui nenhum tipo de regularizaÃ§Ã£o, ou seja, todos os coeficientes das variÃ¡veis independentes sÃ£o ajustados para minimizar o erro quadrÃ¡tico mÃ©dio.\n",
    "- Pode sofrer com problemas de overfitting se houver muitas variÃ¡veis ou multicolinearidade entre elas.\n",
    "\n",
    "#### 2. RegressÃ£o Lasso (Least Absolute Shrinkage and Selection Operator)\n",
    "- Inclui um termo de regularizaÃ§Ã£o baseado na **norma L1** (soma dos valores absolutos dos coeficientes) no cÃ¡lculo da funÃ§Ã£o de custo.\n",
    "- Esse termo forÃ§a alguns coeficientes a se tornarem exatamente zero, o que efetivamente realiza seleÃ§Ã£o de variÃ¡veis.\n",
    "- Ã‰ Ãºtil quando se deseja simplificar o modelo, eliminando variÃ¡veis irrelevantes.\n",
    "\n",
    "#### 3. RegressÃ£o de Ridge\n",
    "- Inclui um termo de regularizaÃ§Ã£o baseado na **norma L2** (soma dos quadrados dos coeficientes) na funÃ§Ã£o de custo.\n",
    "- Esse termo reduz os valores dos coeficientes, mas nÃ£o os zera completamente.\n",
    "- Ã‰ Ãºtil para lidar com multicolinearidade, pois distribui o peso entre as variÃ¡veis correlacionadas.\n",
    "\n",
    "### Resumo\n",
    "- **RegressÃ£o Linear MÃºltipla**: NÃ£o possui regularizaÃ§Ã£o.\n",
    "- **RegressÃ£o Lasso**: Realiza regularizaÃ§Ã£o L1, eliminando variÃ¡veis irrelevantes.\n",
    "- **RegressÃ£o de Ridge**: Utiliza regularizaÃ§Ã£o L2, reduzindo os coeficientes, mas mantendo todas as variÃ¡veis no modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd4df5",
   "metadata": {},
   "source": [
    "â”€â”€â”€ â‹†â‹…â˜†â‹…â‹† â”€â”€â”€  â”€â”€â”€ â‹†â‹…â˜†â‹…â‹† â”€â”€â”€  â”€â”€â”€ â‹†â‹…â˜†â‹…â‹† â”€â”€â”€  â”€â”€â”€ â‹†â‹…â˜†â‹…â‹† â”€â”€â”€  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed02d764",
   "metadata": {},
   "source": [
    "ğŸ‡ºğŸ‡¸  English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3af3e",
   "metadata": {},
   "source": [
    "The **Multiple Linear Regression**, **Lasso Regression**, and **Ridge Regression** are regression techniques used to model the relationship between independent (predictor) variables and a dependent (target) variable. Here are the main differences between them:\n",
    "\n",
    "### 1. Multiple Linear Regression\n",
    "- It is the basic form of linear regression that tries to fit a simple linear model to the data.\n",
    "- It does not include any type of regularization, meaning all coefficients of the independent variables are adjusted to minimize the mean squared error.\n",
    "- It can suffer from overfitting if there are too many variables or multicollinearity among them.\n",
    "\n",
    "### 2. Lasso Regression (Least Absolute Shrinkage and Selection Operator)\n",
    "- It includes a regularization term based on the **L1 norm** (sum of the absolute values of the coefficients) in the cost function.\n",
    "- This term forces some coefficients to become exactly zero, effectively performing variable selection.\n",
    "- It is useful when simplifying the model by eliminating irrelevant variables is desired.\n",
    "\n",
    "### 3. Ridge Regression\n",
    "- It includes a regularization term based on the **L2 norm** (sum of the squared values of the coefficients) in the cost function.\n",
    "- This term reduces the values of the coefficients but does not set them to zero completely.\n",
    "- It is useful for handling multicollinearity as it distributes the weight among correlated variables.\n",
    "\n",
    "### Summary\n",
    "- **Multiple Linear Regression**: No regularization.\n",
    "- **Lasso Regression**: L1 regularization, eliminates irrelevant variables.\n",
    "- **Ridge Regression**: L2 regularization, reduces coefficients but keeps all variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c8a0a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
